{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying a fine-tuned model with Model-As-Service Serverless\n",
    "\n",
    "This notebook shows how to deploy a fine-tuned model serverless on Azure AI Model-As-Service.\n",
    "\n",
    "**Note**: It waits for the fine-tuned model to be available so it is safe running it before the fine-tuning job has completed.\n",
    "\n",
    "#### Model\n",
    "We will use the model fine-tuned in the previous [2_finetune.ipynb](./2_finetune.ipynb) notebook.\n",
    "\n",
    "#### Pre-requisites\n",
    "Same as in the [1_gen.ipynb](./1_gen.ipynb) notebook, you need to subscribe to the Marketplace offering. This should be done already but here is the [documentation](https://aka.ms/raft-llama-31-learn-deploy-405b) in case you worked around this in the previous notebook.\n",
    "\n",
    "The requirements should have been automatically installed if you opened the project in Dev Container or Codespaces, but if not, uncomment the following cell to install the requirements\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "![](./doc/raft-process-deploy.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install azure-ai-ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import (\n",
    "    DefaultAzureCredential,\n",
    "    InteractiveBrowserCredential,\n",
    ")\n",
    "from azure.ai.ml.entities import MarketplaceSubscription, ServerlessEndpoint\n",
    "\n",
    "try:\n",
    "    credential = DefaultAzureCredential()\n",
    "    credential.get_token(\"https://management.azure.com/.default\")\n",
    "except Exception as ex:\n",
    "    credential = InteractiveBrowserCredential()\n",
    "\n",
    "try:\n",
    "    client = MLClient.from_config(credential=credential)\n",
    "except:\n",
    "    print(\"Please create a workspace configuration file in the current directory.\")\n",
    "\n",
    "# Get AzureML workspace object.\n",
    "workspace = client._workspaces.get(client.workspace_name)\n",
    "workspace_id = workspace._workspace_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's figure out the name of the finetuned model from the shared state environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Variables passed by previous notebooks\n",
    "load_dotenv(\".env.state\")\n",
    "\n",
    "FINETUNED_MODEL_NAME = os.getenv(\"FINETUNED_MODEL_NAME\")\n",
    "FINETUNED_MODEL_FORMAT = os.getenv(\"FINETUNED_MODEL_FORMAT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fine-tuning job might still be training so let's wait until the model is ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import wait_for_model\n",
    "\n",
    "print(f\"Waiting for fine tuned model {FINETUNED_MODEL_NAME} to complete training...\")\n",
    "model = wait_for_model(client, FINETUNED_MODEL_NAME)\n",
    "print(f\"Model {FINETUNED_MODEL_NAME} is ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's subscribe to the model, this requires having accepted the provider's Marketplace terms at least once in the Model Catalog UI before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_id = model.properties[\"baseModelId\"]\n",
    "model_id = model.id\n",
    "subscription_name = base_model_id.split(\"/\")[-1].replace(\".\", \"-\").replace(\"_\", \"-\")\n",
    "print(f\"Subscribing to {subscription_name} for model ID {base_model_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Asset ID required to deploy the model is not currently exposed through the Python SDK so we're constructing it using the information we have on hand.\n",
    "\n",
    "**Note**: as we're indirectly constructing the Asset ID blob storage path, the backend might change this and break this code. If this happens, you can figure out what the new expected form is by searching for the Asset ID field in the fine-tuned model's catalog page and adjust the template bellow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_asset_id = f\"azureml://locations/westus3/workspaces/{workspace_id}/{\"/\".join(model.id.split('/')[9:])}\"\n",
    "print(f\"Deploying model asset id {model_asset_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.core.exceptions import ResourceExistsError\n",
    "marketplace_subscription = MarketplaceSubscription(\n",
    "    model_id=base_model_id,\n",
    "    name=subscription_name,\n",
    ")\n",
    "\n",
    "try:\n",
    "    marketplace_subscription = client.marketplace_subscriptions.begin_create_or_update(marketplace_subscription).result()\n",
    "except ResourceExistsError as ex:\n",
    "    print(f\"Marketplace subscription {subscription_name} already exists for model {base_model_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deploy the model as a serverless endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The endpoint name is deterministic based only on the model name which is assumed to contain a hash of the dataset \n",
    "# because if the finetuned model for that specific dataset is already deployed, we don't want to deploy it again\n",
    "endpoint_name = f\"{model.name}\".replace(\".\", \"-\").replace(\"_\", \"-\")[:64]\n",
    "print(f\"Deploying model {model.name} as endpoint {endpoint_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.core.exceptions import ResourceNotFoundError\n",
    "try:\n",
    "    serverless_endpoint = client.serverless_endpoints.get(endpoint_name)\n",
    "    print(f\"Found existing endpoint {endpoint_name}\")\n",
    "except ResourceNotFoundError as ex:\n",
    "    serverless_endpoint = ServerlessEndpoint(name=endpoint_name, model_id=model_asset_id)\n",
    "    serverless_endpoint = client.serverless_endpoints.begin_create_or_update(serverless_endpoint).result()\n",
    "\n",
    "    print(\"Waiting for deployment to complete...\")\n",
    "    serverless_endpoint = ServerlessEndpoint(name=endpoint_name, model_id=model_id)\n",
    "\n",
    "    created_endpoint = client.serverless_endpoints.begin_create_or_update(serverless_endpoint).result()\n",
    "    print(\"Deployment complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's extract the endpoint URL, name and keys and store them in the shared state to pass on to the next notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = client.serverless_endpoints.get(endpoint_name)\n",
    "endpoint_keys = client.serverless_endpoints.get_keys(endpoint_name)\n",
    "\n",
    "# Update the shared `.env.state` env file with the newly deployed finetuned model endpoint\n",
    "from utils import update_state\n",
    "\n",
    "update_state(\"FINETUNED_OPENAI_BASE_URL\", endpoint.scoring_uri)\n",
    "update_state(\"FINETUNED_OPENAI_API_KEY\", endpoint_keys.primary_key)\n",
    "update_state(\"FINETUNED_OPENAI_DEPLOYMENT\", endpoint.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test that the finetuned model is deployed and available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "print(f\"Testing deployed {FINETUNED_MODEL_FORMAT} model at {endpoint.scoring_uri}\")\n",
    "url = f\"{endpoint.scoring_uri}/v1/completions\" if FINETUNED_MODEL_FORMAT == \"completion\" else f\"{endpoint.scoring_uri}/v1/chat/completions\"\n",
    "\n",
    "prompt = \"What do you know?\"\n",
    "payload = {\"max_tokens\": 1024, \"prompt\": [prompt]} if FINETUNED_MODEL_FORMAT == \"completion\" else {\n",
    "    \"messages\":[ { \"role\":\"user\",\"content\":prompt } ],\n",
    "    \"max_tokens\":1024\n",
    "}\n",
    "headers = {\"Content-Type\": \"application/json\", \"Authorization\": endpoint_keys.primary_key}\n",
    "\n",
    "response = requests.post(url, json=payload, headers=headers)\n",
    "\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next step -> Evaluation\n",
    "\n",
    "[./4_eval.ipynb](./4_eval.ipynb) to start evaluating the deployed student model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
