{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Monitor the fine tuning job\n",
    "\n",
    "The training time depends on the number of tokens and number of epochs, typically you can expect a job this size to run for a little over an hour and a half. We have already fine-tuned and deployed a model so you can use it directly without waiting for your fine tuning job to complete.\n",
    "\n",
    "[Fine tuned model](https://oai.azure.com/resource/finetune/ftjob-6d1293138cd844e7bab02a141a60c697/details?wsid=/subscriptions/3c791225-4905-4a40-860b-0a0c9cd2af91/resourceGroups/RG-FineTuning-AIGBBWorkshop/providers/Microsoft.CognitiveServices/accounts/aoai-raft-gbb-workshop&tid=604b58b3-fa4e-4a57-b566-cac3f88a3ae8)\n",
    "\n",
    "[Fine tuned model deployment](https://oai.azure.com/resource/deployments/%2Fsubscriptions%2F3c791225-4905-4a40-860b-0a0c9cd2af91%2FresourceGroups%2FRG-FineTuning-AIGBBWorkshop%2Fproviders%2FMicrosoft.CognitiveServices%2Faccounts%2Faoai-raft-gbb-workshop%2Fdeployments%2Fgpt-4o-mini-ft-raft-banking?wsid=/subscriptions/3c791225-4905-4a40-860b-0a0c9cd2af91/resourceGroups/RG-FineTuning-AIGBBWorkshop/providers/Microsoft.CognitiveServices/accounts/aoai-raft-gbb-workshop&tid=604b58b3-fa4e-4a57-b566-cac3f88a3ae8)\n",
    "\n",
    "You can monitor your fine tuning job from this notebook or in the Azure OpenAI's new studio.\n",
    "\n",
    "Go to Tools > Fine-tuning > Click on your job \n",
    "\n",
    "![alt text](./static/ft_monitor.png \"Azure OpenAI Studio Fine tuning job\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "![](./doc/raft-process-deploy.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can also monitor the job from this notebook**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset name zava-articles\n",
      "Student OpenAI Job ID ftjob-8972c351eabc479691d407c4d2216381\n",
      "Student model name gpt-4.1-nano\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Variables passed by previous notebooks\n",
    "load_dotenv(\".env.state\")\n",
    "\n",
    "job_id = os.getenv(\"STUDENT_OPENAI_JOB_ID\")\n",
    "STUDENT_MODEL_NAME = os.getenv(\"STUDENT_MODEL_NAME\")\n",
    "ds_name = os.getenv(\"DATASET_NAME\")\n",
    "print(f\"Dataset name {ds_name}\")\n",
    "print(f\"Student OpenAI Job ID {job_id}\")\n",
    "print(f\"Student model name {STUDENT_MODEL_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.identity import get_bearer_token_provider\n",
    "\n",
    "aoai_endpoint = os.getenv(\"FINETUNE_AZURE_OPENAI_ENDPOINT\")\n",
    "\n",
    "# Authenticate using the default Azure credential chain\n",
    "azure_credential = DefaultAzureCredential()\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  azure_endpoint = aoai_endpoint,\n",
    "  api_version = \"2024-05-01-preview\",  # This API version or later is required to access seed/events/checkpoint features\n",
    "  azure_ad_token_provider = get_bearer_token_provider(\n",
    "    azure_credential, \"https://cognitiveservices.azure.com/.default\"\n",
    "  )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning job ftjob-8972c351eabc479691d407c4d2216381 finished with status: succeeded\n",
      "Checking other fine-tune jobs for this resource.\n",
      "Found 2 fine-tune jobs.\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Get the status of our fine-tuning job.\n",
    "response = client.fine_tuning.jobs.retrieve(job_id)\n",
    "\n",
    "status = response.status\n",
    "\n",
    "# If the job isn't done yet, poll it every 10 seconds.\n",
    "while status not in [\"succeeded\", \"failed\"]:\n",
    "    response = client.fine_tuning.jobs.retrieve(job_id)\n",
    "    #print(response.model_dump_json(indent=2))\n",
    "    print(f\"Waiting for job {job_id} to complete\")\n",
    "    print(\"Elapsed time: {} minutes {} seconds\".format(int((time.time() - start_time) // 60), int((time.time() - start_time) % 60)))\n",
    "    status = response.status\n",
    "    print(f'Status: {status}')\n",
    "    clear_output(wait=True)\n",
    "    time.sleep(5)\n",
    "\n",
    "print(f'Fine-tuning job {job_id} finished with status: {status}')\n",
    "\n",
    "# List all fine-tuning jobs for this resource.\n",
    "print('Checking other fine-tune jobs for this resource.')\n",
    "response = client.fine_tuning.jobs.list()\n",
    "print(f'Found {len(response.data)} fine-tune jobs.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fine_tuned_model = gpt-4.1-nano-2025-04-14.ft-8972c351eabc479691d407c4d2216381\n"
     ]
    }
   ],
   "source": [
    "# Retrieve fine_tuned_model name\n",
    "response = client.fine_tuning.jobs.retrieve(job_id)\n",
    "fine_tuned_model = response.fine_tuned_model\n",
    "print(f\"fine_tuned_model = {fine_tuned_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Analyze the fine tuned model in Azure OpenAI Studio\n",
    "\n",
    "Head here for a fine tuned model in the shared AI GBB tenant:\n",
    "[Fine tuning job](https://oai.azure.com/resource/finetune/ftjob-6d1293138cd844e7bab02a141a60c697/details?wsid=/subscriptions/3c791225-4905-4a40-860b-0a0c9cd2af91/resourceGroups/RG-FineTuning-AIGBBWorkshop/providers/Microsoft.CognitiveServices/accounts/aoai-raft-gbb-workshop&tid=604b58b3-fa4e-4a57-b566-cac3f88a3ae8)\n",
    "\n",
    "##### 4.a Training plots\n",
    "\n",
    "When the model is done training, head to your Azure OpenAI Studio to analyze your model training metrics.\n",
    "\n",
    "Two charts are available to analyze your fine tuning job and sanity check that the training went smoothly:\n",
    "- Loss curve: Value of the loss function (how wrong the model is) over time during training process --> this curve should go down over time as the model weights converge towards the optimum. \n",
    "- Token Accuracy: Shows the accuracy of the model's predictions at the token level (e.g., words or subwords) over time during training. A higher token accuracy suggests that the model is better able to capture the nuances of the language and generate more accurate text.\n",
    "\n",
    "Each of these charts has the metrics computed both on the training data and on the validation set. \n",
    "\n",
    "To analyze these plots, one should look for the following:\n",
    "\n",
    "- A smooth curve: A smooth curve indicates that the model is learning consistently. Sharp changes or spikes in the curve could indicate issues with the learning rate or data preprocessing.\n",
    "- Plateau: A plateau in the curve indicates that the model has stopped improving and further training may not be necessary.\n",
    "- Overfitting: If the training loss continues to decrease but the validation loss starts to increase, it could be a sign of overfitting. This means that the model is not generalizing well to new data and may perform poorly on unseen data.\n",
    "- Underfitting: If both the training and validation loss remain high, it could be a sign of underfitting. This means that the model is not learning the patterns in the data well enough and may need a more complex - architecture or more training data.\n",
    "- Optimal stopping point: By analyzing the loss curve and token accuracy plot, one can determine the optimal stopping point for training, where the model has reached its best performance without overfitting.\n",
    "\n",
    "Now head to the studio and ensure your curves look roughly like the below\n",
    "\n",
    "\n",
    "\n",
    "![Alt text](./static/ft_metrics.png \"AOAI training plots\")\n",
    "\n",
    "##### 4.b Model Checkpoints\n",
    "\n",
    "In the Studio, go to the checkpoints tab, you'll see a model checkpoint corresponding to each completed epoch. A checkpoint is a fully functional version of a model which can both be deployed and used as the target model for subsequent fine-tuning jobs. Checkpoints can be particularly useful, as they can provide a snapshot of your model prior to overfitting having occurred. \n",
    "\n",
    "![Alt text](./static/ft_checkpoints.png \"AOAI training plots\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Create a new deployment with the fine tuned model\n",
    "\n",
    "When the fine-tuning job succeeds, the value of the fine_tuned_model variable in the response body is set to the name of your customized model. Your model is now also available for discovery from the list Models API. However, you can't issue completion calls to your customized model until your customized model is deployed. You must deploy your customized model to make it available for use with completion calls\n",
    "\n",
    "#### 5.a From the notebook\n",
    "To create a new deployment from a notebook, you'll need an access token from Azure, \n",
    "Open a terminal and run:\n",
    "\n",
    "`az login`\n",
    "\n",
    "`az account get-access-token`\n",
    "\n",
    "paste the token in the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student deployment name ft-raft-gpt-4.1-nano-zava-articles\n",
      "Updating state file with STUDENT_DEPLOYMENT_NAME=ft-raft-gpt-4.1-nano-zava-articles\n",
      "Updating state file with STUDENT_AZURE_OPENAI_ENDPOINT=https://aoai-rogteyz-cvi-brk443-2.openai.azure.com/\n"
     ]
    }
   ],
   "source": [
    "from utils import update_state\n",
    "STUDENT_DEPLOYMENT_NAME = f\"ft-raft-{STUDENT_MODEL_NAME}-{ds_name}\"\n",
    "print(f\"Student deployment name {STUDENT_DEPLOYMENT_NAME}\")\n",
    "update_state(\"STUDENT_DEPLOYMENT_NAME\", STUDENT_DEPLOYMENT_NAME)\n",
    "update_state(\"STUDENT_AZURE_OPENAI_ENDPOINT\", aoai_endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy fine-tuned model\n",
    "import requests\n",
    "import json\n",
    "\n",
    "access_token = azure_credential.get_token(\"https://management.azure.com/.default\")\n",
    "\n",
    "token = access_token.token\n",
    "subscription = os.getenv(\"AZURE_SUBSCRIPTION_ID\")\n",
    "resource_group = os.getenv(\"AZURE_RESOURCE_GROUP\")\n",
    "resource_name = aoai_endpoint.split(\"https://\")[1].split(\".\")[0]\n",
    "\n",
    "deploy_params = {'api-version': \"2023-05-01\"}\n",
    "deploy_headers = {'Authorization': 'Bearer {}'.format(token), 'Content-Type': 'application/json'}\n",
    "\n",
    "deploy_data = {\n",
    "    \"sku\": {\"name\": \"developertier\", \"capacity\": 4},\n",
    "    \"properties\": {\n",
    "        \"model\": {\n",
    "            \"format\": \"OpenAI\",\n",
    "            \"name\": fine_tuned_model, #retrieve this value from the previous call, it will look like gpt-35-turbo-0613.ft-b044a9d3cf9c4228b5d393567f693b83\n",
    "            \"version\": \"1\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "deploy_data = json.dumps(deploy_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a new deployment...\n",
      "<Response [201]>\n",
      "Created\n",
      "{'id': '/subscriptions/7a880728-70d3-49d0-adde-4250716cfd94/resourceGroups/rg-cvi-brk443-2/providers/Microsoft.CognitiveServices/accounts/aoai-rogteyz-cvi-brk443-2/deployments/ft-raft-gpt-4.1-nano-zava-articles', 'type': 'Microsoft.CognitiveServices/accounts/deployments', 'name': 'ft-raft-gpt-4.1-nano-zava-articles', 'sku': {'name': 'developertier', 'capacity': 4}, 'properties': {'model': {'format': 'OpenAI', 'name': 'gpt-4.1-nano-2025-04-14.ft-8972c351eabc479691d407c4d2216381', 'version': '1'}, 'versionUpgradeOption': 'NoAutoUpgrade', 'capabilities': {'chatCompletion': 'true', 'area': 'US', 'responses': 'true', 'assistants': 'true'}, 'provisioningState': 'Creating', 'rateLimits': [{'key': 'request', 'renewalPeriod': 60, 'count': 4}, {'key': 'token', 'renewalPeriod': 60, 'count': 4000}]}, 'systemData': {'createdBy': 'cedricvidal@caai2510.onmicrosoft.com', 'createdByType': 'User', 'createdAt': '2025-08-28T00:42:29.4741964Z', 'lastModifiedBy': 'cedricvidal@caai2510.onmicrosoft.com', 'lastModifiedByType': 'User', 'lastModifiedAt': '2025-08-28T00:42:29.4741964Z'}, 'etag': '\"4e005b43-d0e2-4adf-a30b-15deec9a0490\"'}\n"
     ]
    }
   ],
   "source": [
    "request_url = f'https://management.azure.com/subscriptions/{subscription}/resourceGroups/{resource_group}/providers/Microsoft.CognitiveServices/accounts/{resource_name}/deployments/{STUDENT_DEPLOYMENT_NAME}'\n",
    "\n",
    "print('Creating a new deployment...')\n",
    "\n",
    "r = requests.put(request_url, params=deploy_params, headers=deploy_headers, data=deploy_data)\n",
    "\n",
    "print(r)\n",
    "print(r.reason)\n",
    "print(r.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wait for deployment to complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '/subscriptions/7a880728-70d3-49d0-adde-4250716cfd94/resourceGroups/rg-cvi-brk443-2/providers/Microsoft.CognitiveServices/accounts/aoai-rogteyz-cvi-brk443-2/deployments/ft-raft-gpt-4.1-nano-zava-articles', 'type': 'Microsoft.CognitiveServices/accounts/deployments', 'name': 'ft-raft-gpt-4.1-nano-zava-articles', 'sku': {'name': 'developertier', 'capacity': 4}, 'properties': {'model': {'format': 'OpenAI', 'name': 'gpt-4.1-nano-2025-04-14.ft-8972c351eabc479691d407c4d2216381', 'version': '1'}, 'versionUpgradeOption': 'NoAutoUpgrade', 'capabilities': {'chatCompletion': 'true', 'area': 'US', 'responses': 'true', 'assistants': 'true'}, 'provisioningState': 'Succeeded', 'rateLimits': [{'key': 'request', 'renewalPeriod': 60, 'count': 4}, {'key': 'token', 'renewalPeriod': 60, 'count': 4000}]}, 'systemData': {'createdBy': 'cedricvidal@caai2510.onmicrosoft.com', 'createdByType': 'User', 'createdAt': '2025-08-28T00:42:29.4741964Z', 'lastModifiedBy': 'cedricvidal@caai2510.onmicrosoft.com', 'lastModifiedByType': 'User', 'lastModifiedAt': '2025-08-28T00:42:29.4741964Z'}, 'etag': '\"4e005b43-d0e2-4adf-a30b-15deec9a0490\"'}\n",
      "Deployment ft-raft-gpt-4.1-nano-zava-articles finished with status: Succeeded\n"
     ]
    }
   ],
   "source": [
    "def retrieve_deployment(url):\n",
    "    return requests.get(url, params=deploy_params, headers=deploy_headers).json()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Get the status of our fine-tuning job.\n",
    "response = retrieve_deployment(request_url)\n",
    "print(response)\n",
    "\n",
    "status = response['properties']['provisioningState']\n",
    "\n",
    "# If the job isn't done yet, poll it every 10 seconds.\n",
    "while status.lower() not in [\"succeeded\", \"failed\"]:\n",
    "    response = retrieve_deployment(request_url)\n",
    "    #print(response.model_dump_json(indent=2))\n",
    "    print(f\"Waiting for model {STUDENT_DEPLOYMENT_NAME} deployment to complete\")\n",
    "    print(\"Elapsed time: {} minutes {} seconds\".format(int((time.time() - start_time) // 60), int((time.time() - start_time) % 60)))\n",
    "    status = response['properties']['provisioningState']\n",
    "    print(f'Status: {status}')\n",
    "    clear_output(wait=True)\n",
    "    time.sleep(5)\n",
    "\n",
    "print(f'Deployment {STUDENT_DEPLOYMENT_NAME} finished with status: {status}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating state file with STUDENT_AZURE_OPENAI_DEPLOYMENT=ft-raft-gpt-4.1-nano-zava-articles\n"
     ]
    }
   ],
   "source": [
    "from utils import update_state\n",
    "update_state(\"STUDENT_AZURE_OPENAI_DEPLOYMENT\", STUDENT_DEPLOYMENT_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next step -> Evaluation\n",
    "\n",
    "[./4_eval.ipynb](./4_eval.ipynb) to start evaluating the deployed student model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
