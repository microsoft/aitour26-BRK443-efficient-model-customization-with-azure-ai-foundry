{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b18b4e33",
   "metadata": {},
   "source": [
    "# Supervised Fine-Tuning - Improve Tone & Style\n",
    "\n",
    "**Pre-Requisites**\n",
    "\n",
    "1. You have an Azure AI Foundry project with GPT-4.1 model deployed\n",
    "1. You have created the `.env` file and updated it with relevant environment variables\n",
    "1. You have authenticated with `az login` from your GitHub Codespaces environment.\n",
    "\n",
    "**Objectives**\n",
    "\n",
    "In this notebook, you will learn to fine-tune a base model (gpt-4.1) with domain-specific data (Zava Q&A) to adapt model behavior to suit a desired business objective (\"Improve Zava chatbot tone & style\"). \n",
    "\n",
    "**Process**\n",
    "\n",
    "The figure shows the basic workflow. Explore [Documentation](https://learn.microsoft.com/azure/ai-foundry/openai/tutorials/fine-tune?tabs=bash#create-a-sample-dataset) for more details - then scroll down to walk through these steps for our Zava use case.\n",
    "\n",
    "![SFT](./../../../docs/slides/14.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84eecbc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Zava Customization \n",
    "\n",
    "Here is how these steps map to our Zava use case. We have used GPT-4.1 for our customization experiments so far, so let's keep going.\n",
    "\n",
    "| Step | Description |\n",
    "|:---|:---|\n",
    "| 1. Decide Vision and Scope | Improve the tone & style of the Cora chatbot to reflect Zava requirements |\n",
    "| 2. Choose Base Model | Start with GPT-4.1 (popular LLM, text-generation task, question-answering task) |\n",
    "| 3. Choose Fine-Tuning Technique | Supervised Fine Tuning - training model with examples of desired tone & style|\n",
    "| 4. Curate Fine-Tuning Dataset | Use ~50 samples for demo - real-world usage needs 100s and 1000s of samples|\n",
    "| 5. Run Fine-Tuning Job | Load training data, set hyperparameters - execute job (and monitor progress) |\n",
    "| 6. Evaluate Fine-Tuned Model | Discuss built-in evaluators (coherence, fluency) vs. custom ones (politeness) |\n",
    "| 7. Deploy Fine-Tuned Model For Use | Deploy with Developer Tier for testing - delete when done (to save cost)|\n",
    "| | |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200cf758",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Create The Dataset\n",
    "\n",
    "**What does the data look like?**\n",
    "\n",
    "We need a specially formatted JSONL training file where each line provides a JSON-formatted \"example\" for our training needs. Having this formatted correctly is critical! Note that each \"line\" has the _system_ message along with a _user_ question and the _assistant_ response.\n",
    "\n",
    "```json\n",
    "{\"messages\": [{\"role\": \"system\", \"content\": \"Cora is a polite, factual and helpful assistant for Zava customers.\"}, {\"role\": \"user\", \"content\": \"I'm painting over rust - what spray paint should I use?\"}, {\"role\": \"assistant\", \"content\": Perfect! Rust Prevention Spray at $10 applies directly over rust. Want prep tips?\"}]}\n",
    "```\n",
    "...\n",
    "\n",
    "**How much data do we need?**\n",
    "\n",
    "Real-world fine-tuning jobs using SFT will need thousands of training samples. In our case, for this demo, we create just 50 samples, allowing us to split them into two files with 25 training and 25 validation samples. Doubling the number of samples can result in a _linear increase in model quality_ **but** it also requires the samples to be of high quality. Otherwise \"garbage in, garbage out\"\n",
    "\n",
    "...\n",
    "\n",
    "**How can we create this data?**\n",
    "\n",
    "You can get the data from historical records if you already have the relevant service running (e.g., customer service logs). Or, you can generate synthetic data that reflects the task or domain specific behavior with a curated set of samples. We will use the second option, creating the synthetic data by using GitHub Copilot Agent Mode, with the product data.\n",
    "\n",
    "1. Create 50+ sample question-answers in JSONL format (we created 52)\n",
    "1. Divide them into `sft_training.jsonl` and `sft_validation.jsonl` files\n",
    "1. We used an 80-20 split - 42 training and 8 validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ff3216",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Prepare For Fine-Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6814da",
   "metadata": {},
   "source": [
    "### 3.1 Check Libraries\n",
    "\n",
    "Make sure the required Python libraries were installed. This should be done automatically when using GitHub Codespaces from this repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e590ba50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All required packages are available!\n"
     ]
    }
   ],
   "source": [
    "# STEP 1: Check that required Python packages are installed\n",
    "try:\n",
    "    import openai\n",
    "    import requests\n",
    "    import numpy\n",
    "    import tiktoken\n",
    "    print(\"All required packages are available!\")\n",
    "except ImportError as e:\n",
    "    print(f\"Missing required package: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf16fa7c",
   "metadata": {},
   "source": [
    "### 3.2 Check Env Variables\n",
    "\n",
    "We need the Azure OpenAI endpoint and key values to make calls against our deployed model. We will have set these earlier, when creating the Azure AI Foundry project. Visit Azure AI Foundry (https://ai.azure.com) and go to the Project Overview page for this project if you need to refresh them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f044b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning model: gpt-4.1\n"
     ]
    }
   ],
   "source": [
    "# STEP 2: Check that required environment variables are set\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Read the Environment Variables (set previously)\n",
    "openai_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "openai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "\n",
    "# Set model name used for fine-tuning here\n",
    "model_name = \"gpt-4.1\"\n",
    "print(f\"Fine-tuning model: {model_name}\")\n",
    "\n",
    "# If missing, print a warning\n",
    "if not openai_key:\n",
    "    print(\"‚ö†Ô∏è Warning: AZURE_OPENAI_API_KEY environment variable is not set.\")\n",
    "if not openai_endpoint:\n",
    "    print(\"‚ö†Ô∏è Warning: AZURE_OPENAI_ENDPOINT environment variable is not set.\")\n",
    "if not api_version:\n",
    "    print(\"‚ö†Ô∏è Warning: AZURE_OPENAI_API_VERSION environment variable is not set.\")  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cff04b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 3.3. Run Checks On Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88fb1083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set File names once\n",
    "training_file_name = 'sft_training.jsonl'\n",
    "validation_file_name = 'sft_validation.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d806159d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples in training set: 40\n",
      "First example in training set:\n",
      "{'role': 'system', 'content': 'Cora is a polite, factual and helpful assistant for Zava customers.'}\n",
      "{'role': 'user', 'content': 'Is water-based polyurethane better than oil-based?'}\n",
      "{'role': 'assistant', 'content': 'ü§î Both have benefits! Water-based at $43 dries faster, oil-based at $34 gives amber tone. Which matters most?'}\n",
      "\n",
      "Number of examples in validation set: 11\n",
      "First example in validation set:\n",
      "{'role': 'system', 'content': 'Cora is a polite, factual and helpful assistant for Zava customers.'}\n",
      "{'role': 'user', 'content': 'How much does the Paint Spray Gun cost?'}\n",
      "{'role': 'assistant', 'content': 'üîß Great tool! The Paint Spray Gun is $89.99 with professional HVLP coverage. Compatible paints?'}\n"
     ]
    }
   ],
   "source": [
    "# Run preliminary checks\n",
    "\n",
    "import json\n",
    "\n",
    "# Load the training set\n",
    "with open(training_file_name, 'r', encoding='utf-8') as f:\n",
    "    training_dataset = [json.loads(line) for line in f]\n",
    "\n",
    "# Training dataset stats\n",
    "print(\"Number of examples in training set:\", len(training_dataset))\n",
    "print(\"First example in training set:\")\n",
    "for message in training_dataset[0][\"messages\"]:\n",
    "    print(message)\n",
    "\n",
    "# Load the validation set\n",
    "with open(validation_file_name, 'r', encoding='utf-8') as f:\n",
    "    validation_dataset = [json.loads(line) for line in f]\n",
    "\n",
    "# Validation dataset stats\n",
    "print(\"\\nNumber of examples in validation set:\", len(validation_dataset))\n",
    "print(\"First example in validation set:\")\n",
    "for message in validation_dataset[0][\"messages\"]:\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ac5cb5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3.4 Validate Token Counts (with TikToken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "421a3dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: sft_training.jsonl\n",
      "\n",
      "#### Distribution of total tokens:\n",
      "min / max: 56, 72\n",
      "mean / median: 62.125, 61.5\n",
      "p5 / p95: 59.0, 65.1\n",
      "\n",
      "#### Distribution of assistant tokens:\n",
      "min / max: 19, 30\n",
      "mean / median: 23.525, 23.0\n",
      "p5 / p95: 20.9, 26.1\n",
      "**************************************************\n",
      "Processing file: sft_validation.jsonl\n",
      "\n",
      "#### Distribution of total tokens:\n",
      "min / max: 57, 70\n",
      "mean / median: 62.27272727272727, 62.0\n",
      "p5 / p95: 60.0, 64.0\n",
      "\n",
      "#### Distribution of assistant tokens:\n",
      "min / max: 20, 28\n",
      "mean / median: 23.272727272727273, 23.0\n",
      "p5 / p95: 22.0, 25.0\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "# Validate token counts\n",
    "\n",
    "import json\n",
    "import tiktoken\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "encoding = tiktoken.get_encoding(\"o200k_base\") # default encoding for gpt-4o models. This requires the latest version of tiktoken to be installed.\n",
    "\n",
    "def num_tokens_from_messages(messages, tokens_per_message=3, tokens_per_name=1):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += tokens_per_message\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":\n",
    "                num_tokens += tokens_per_name\n",
    "    num_tokens += 3\n",
    "    return num_tokens\n",
    "\n",
    "def num_assistant_tokens_from_messages(messages):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        if message[\"role\"] == \"assistant\":\n",
    "            num_tokens += len(encoding.encode(message[\"content\"]))\n",
    "    return num_tokens\n",
    "\n",
    "def print_distribution(values, name):\n",
    "    print(f\"\\n#### Distribution of {name}:\")\n",
    "    print(f\"min / max: {min(values)}, {max(values)}\")\n",
    "    print(f\"mean / median: {np.mean(values)}, {np.median(values)}\")\n",
    "    print(f\"p5 / p95: {np.quantile(values, 0.1)}, {np.quantile(values, 0.9)}\")\n",
    "\n",
    "files = [training_file_name, validation_file_name]\n",
    "\n",
    "for file in files:\n",
    "    print(f\"Processing file: {file}\")\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        dataset = [json.loads(line) for line in f]\n",
    "\n",
    "    total_tokens = []\n",
    "    assistant_tokens = []\n",
    "\n",
    "    for ex in dataset:\n",
    "        messages = ex.get(\"messages\", {})\n",
    "        total_tokens.append(num_tokens_from_messages(messages))\n",
    "        assistant_tokens.append(num_assistant_tokens_from_messages(messages))\n",
    "\n",
    "    print_distribution(total_tokens, \"total tokens\")\n",
    "    print_distribution(assistant_tokens, \"assistant tokens\")\n",
    "    print('*' * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b6d47e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Upload Fine Tuning Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dca2ebcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training file ID: file-f234ff928f344a998497193d27f19239\n",
      "Validation file ID: file-017e3d8843104ac880e523b42624ee46\n"
     ]
    }
   ],
   "source": [
    "# Upload fine-tuning files\n",
    "\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "  api_key = os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "  api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    ")\n",
    "\n",
    "# Upload the training and validation dataset files to Azure OpenAI with the SDK.\n",
    "\n",
    "training_response = client.files.create(\n",
    "    file = open(training_file_name, \"rb\"), purpose=\"fine-tune\"\n",
    ")\n",
    "training_file_id = training_response.id\n",
    "\n",
    "validation_response = client.files.create(\n",
    "    file = open(validation_file_name, \"rb\"), purpose=\"fine-tune\"\n",
    ")\n",
    "validation_file_id = validation_response.id\n",
    "\n",
    "print(\"Training file ID:\", training_file_id)\n",
    "print(\"Validation file ID:\", validation_file_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73dfd8ff",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Begin Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03603de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: ftjob-d04bf4eb1348467fa3678fdae1e63dc8\n",
      "Status: pending\n",
      "{\n",
      "  \"id\": \"ftjob-d04bf4eb1348467fa3678fdae1e63dc8\",\n",
      "  \"created_at\": 1756144701,\n",
      "  \"error\": null,\n",
      "  \"fine_tuned_model\": null,\n",
      "  \"finished_at\": null,\n",
      "  \"hyperparameters\": {\n",
      "    \"batch_size\": -1,\n",
      "    \"learning_rate_multiplier\": 2.0,\n",
      "    \"n_epochs\": -1\n",
      "  },\n",
      "  \"model\": \"gpt-4.1-2025-04-14\",\n",
      "  \"object\": \"fine_tuning.job\",\n",
      "  \"organization_id\": null,\n",
      "  \"result_files\": null,\n",
      "  \"seed\": 101,\n",
      "  \"status\": \"pending\",\n",
      "  \"trained_tokens\": null,\n",
      "  \"training_file\": \"file-f234ff928f344a998497193d27f19239\",\n",
      "  \"validation_file\": \"file-017e3d8843104ac880e523b42624ee46\",\n",
      "  \"estimated_finish\": 1756145781,\n",
      "  \"integrations\": null,\n",
      "  \"metadata\": null,\n",
      "  \"method\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Submit fine-tuning training job\n",
    "\n",
    "response = client.fine_tuning.jobs.create(\n",
    "    training_file = training_file_id,\n",
    "    validation_file = validation_file_id,\n",
    "    model = model_name, # Enter base model name. Note that in Azure OpenAI the model name contains dashes and cannot contain dot/period characters.\n",
    "    seed = 101 # 105 # seed parameter controls reproducibility of the fine-tuning job. If no seed is specified one will be generated automatically.\n",
    ")\n",
    "\n",
    "job_id = response.id\n",
    "\n",
    "# You can use the job ID to monitor the status of the fine-tuning job.\n",
    "# The fine-tuning job will take some time to start and complete.\n",
    "\n",
    "print(\"Job ID:\", response.id)\n",
    "print(\"Status:\", response.status)\n",
    "print(response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432eabcb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1bbb3b28",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Track Training Job Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3fe358e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning job ftjob-d04bf4eb1348467fa3678fdae1e63dc8 finished with status: succeeded\n",
      "Checking other fine-tune jobs for this resource.\n",
      "Found 2 fine-tune jobs.\n"
     ]
    }
   ],
   "source": [
    "# Track training status\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Get the status of our fine-tuning job.\n",
    "response = client.fine_tuning.jobs.retrieve(job_id)\n",
    "\n",
    "status = response.status\n",
    "\n",
    "# If the job isn't done yet, poll it every 10 seconds.\n",
    "while status not in [\"succeeded\", \"failed\"]:\n",
    "    time.sleep(10)\n",
    "\n",
    "    response = client.fine_tuning.jobs.retrieve(job_id)\n",
    "    print(response.model_dump_json(indent=2))\n",
    "    print(\"Elapsed time: {} minutes {} seconds\".format(int((time.time() - start_time) // 60), int((time.time() - start_time) % 60)))\n",
    "    status = response.status\n",
    "    print(f'Status: {status}')\n",
    "    clear_output(wait=True)\n",
    "\n",
    "print(f'Fine-tuning job {job_id} finished with status: {status}')\n",
    "\n",
    "# List all fine-tuning jobs for this resource.\n",
    "print('Checking other fine-tune jobs for this resource.')\n",
    "response = client.fine_tuning.jobs.list()\n",
    "print(f'Found {len(response.data)} fine-tune jobs.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf9e7e2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. List Fine-Tuning Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb103182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"data\": [\n",
      "    {\n",
      "      \"id\": \"ftevent-8d2a8afbb4e84136a5d86e5c531fcd90\",\n",
      "      \"created_at\": 1756149364,\n",
      "      \"level\": \"info\",\n",
      "      \"message\": \"Training tokens billed: 8000\",\n",
      "      \"object\": \"fine_tuning.job.event\",\n",
      "      \"data\": null,\n",
      "      \"type\": \"message\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"ftevent-9c82369fd83d4035bbbcd22a64db2cbf\",\n",
      "      \"created_at\": 1756149364,\n",
      "      \"level\": \"info\",\n",
      "      \"message\": \"Model Evaluation Passed.\",\n",
      "      \"object\": \"fine_tuning.job.event\",\n",
      "      \"data\": null,\n",
      "      \"type\": \"message\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"ftevent-efa8791468cd4f15b1885e437d9d445d\",\n",
      "      \"created_at\": 1756149364,\n",
      "      \"level\": \"info\",\n",
      "      \"message\": \"Completed results file: file-c39c3cfde22648948c6fdd6cfc1279ce\",\n",
      "      \"object\": \"fine_tuning.job.event\",\n",
      "      \"data\": null,\n",
      "      \"type\": \"message\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"ftevent-e616e3bc6ddf431984acfa770c40123d\",\n",
      "      \"created_at\": 1756149343,\n",
      "      \"level\": \"info\",\n",
      "      \"message\": \"Job succeeded.\",\n",
      "      \"object\": \"fine_tuning.job.event\",\n",
      "      \"data\": null,\n",
      "      \"type\": \"message\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"ftevent-008dde4074f21d6008dde4074f21d600\",\n",
      "      \"created_at\": 1756147420,\n",
      "      \"level\": \"info\",\n",
      "      \"message\": \"Step 120: training loss=0.8280026912689209\",\n",
      "      \"object\": \"fine_tuning.job.event\",\n",
      "      \"data\": {\n",
      "        \"step\": 120,\n",
      "        \"train_loss\": 0.8280026912689209,\n",
      "        \"train_mean_token_accuracy\": 0.75,\n",
      "        \"valid_loss\": 2.4705605873694787,\n",
      "        \"valid_mean_token_accuracy\": 0.5,\n",
      "        \"full_valid_loss\": 1.3124475890783955,\n",
      "        \"full_valid_mean_token_accuracy\": 0.6474820143884892\n",
      "      },\n",
      "      \"type\": \"metrics\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"ftevent-008dde407492bf5008dde407492bf500\",\n",
      "      \"created_at\": 1756147410,\n",
      "      \"level\": \"info\",\n",
      "      \"message\": \"Step 110: training loss=0.7519499659538269\",\n",
      "      \"object\": \"fine_tuning.job.event\",\n",
      "      \"data\": {\n",
      "        \"step\": 110,\n",
      "        \"train_loss\": 0.7519499659538269,\n",
      "        \"train_mean_token_accuracy\": 0.8148148059844971,\n",
      "        \"valid_loss\": 1.093326644897461,\n",
      "        \"valid_mean_token_accuracy\": 0.72\n",
      "      },\n",
      "      \"type\": \"metrics\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"ftevent-008dde407433614008dde40743361400\",\n",
      "      \"created_at\": 1756147400,\n",
      "      \"level\": \"info\",\n",
      "      \"message\": \"Step 100: training loss=1.1578313112258911\",\n",
      "      \"object\": \"fine_tuning.job.event\",\n",
      "      \"data\": {\n",
      "        \"step\": 100,\n",
      "        \"train_loss\": 1.1578313112258911,\n",
      "        \"train_mean_token_accuracy\": 0.6666666865348816,\n",
      "        \"valid_loss\": 1.2268333435058594,\n",
      "        \"valid_mean_token_accuracy\": 0.6923076923076923\n",
      "      },\n",
      "      \"type\": \"metrics\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"ftevent-008dde4073d4033008dde4073d403300\",\n",
      "      \"created_at\": 1756147390,\n",
      "      \"level\": \"info\",\n",
      "      \"message\": \"Step 90: training loss=1.0343395471572876\",\n",
      "      \"object\": \"fine_tuning.job.event\",\n",
      "      \"data\": {\n",
      "        \"step\": 90,\n",
      "        \"train_loss\": 1.0343395471572876,\n",
      "        \"train_mean_token_accuracy\": 0.6800000071525574,\n",
      "        \"valid_loss\": 1.2922032674153645,\n",
      "        \"valid_mean_token_accuracy\": 0.625\n",
      "      },\n",
      "      \"type\": \"metrics\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"ftevent-008dde407374a52008dde407374a5200\",\n",
      "      \"created_at\": 1756147380,\n",
      "      \"level\": \"info\",\n",
      "      \"message\": \"Step 80: training loss=1.4701025485992432\",\n",
      "      \"object\": \"fine_tuning.job.event\",\n",
      "      \"data\": {\n",
      "        \"step\": 80,\n",
      "        \"train_loss\": 1.4701025485992432,\n",
      "        \"train_mean_token_accuracy\": 0.6190476417541504,\n",
      "        \"valid_loss\": 1.2183958689371746,\n",
      "        \"valid_mean_token_accuracy\": 0.6666666666666666,\n",
      "        \"full_valid_loss\": 1.321454672504672,\n",
      "        \"full_valid_mean_token_accuracy\": 0.6330935251798561\n",
      "      },\n",
      "      \"type\": \"metrics\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"ftevent-008dde407315471008dde40731547100\",\n",
      "      \"created_at\": 1756147370,\n",
      "      \"level\": \"info\",\n",
      "      \"message\": \"Step 70: training loss=1.410714864730835\",\n",
      "      \"object\": \"fine_tuning.job.event\",\n",
      "      \"data\": {\n",
      "        \"step\": 70,\n",
      "        \"train_loss\": 1.410714864730835,\n",
      "        \"train_mean_token_accuracy\": 0.695652186870575,\n",
      "        \"valid_loss\": 2.0692137908935546,\n",
      "        \"valid_mean_token_accuracy\": 0.48\n",
      "      },\n",
      "      \"type\": \"metrics\"\n",
      "    }\n",
      "  ],\n",
      "  \"has_more\": true,\n",
      "  \"object\": \"list\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = client.fine_tuning.jobs.list_events(fine_tuning_job_id=job_id, limit=10)\n",
    "print(response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c442ad53",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. List Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c89c9812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"data\": [\n",
      "    {\n",
      "      \"id\": \"ftchkpt-ed43e285d8174b8b8e7230fd0fff49ab\",\n",
      "      \"created_at\": 1756147966,\n",
      "      \"fine_tuned_model_checkpoint\": \"gpt-4.1-2025-04-14.ft-d04bf4eb1348467fa3678fdae1e63dc8\",\n",
      "      \"fine_tuning_job_id\": \"ftjob-d04bf4eb1348467fa3678fdae1e63dc8\",\n",
      "      \"metrics\": {\n",
      "        \"full_valid_loss\": 1.3124475890783955,\n",
      "        \"full_valid_mean_token_accuracy\": 0.6474820143884892,\n",
      "        \"step\": 120.0,\n",
      "        \"train_loss\": 0.8280026912689209,\n",
      "        \"train_mean_token_accuracy\": 0.75,\n",
      "        \"valid_loss\": 2.4705605873694787,\n",
      "        \"valid_mean_token_accuracy\": 0.5\n",
      "      },\n",
      "      \"object\": \"fine_tuning.job.checkpoint\",\n",
      "      \"step_number\": 120\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"ftchkpt-ccbedbc3f035472b9e01004f51247ce4\",\n",
      "      \"created_at\": 1756147775,\n",
      "      \"fine_tuned_model_checkpoint\": \"gpt-4.1-2025-04-14.ft-d04bf4eb1348467fa3678fdae1e63dc8:ckpt-step-80\",\n",
      "      \"fine_tuning_job_id\": \"ftjob-d04bf4eb1348467fa3678fdae1e63dc8\",\n",
      "      \"metrics\": {\n",
      "        \"full_valid_loss\": 1.321454672504672,\n",
      "        \"full_valid_mean_token_accuracy\": 0.6330935251798561,\n",
      "        \"step\": 80.0,\n",
      "        \"train_loss\": 1.4701025485992432,\n",
      "        \"train_mean_token_accuracy\": 0.6190476417541504,\n",
      "        \"valid_loss\": 1.2183958689371746,\n",
      "        \"valid_mean_token_accuracy\": 0.6666666666666666\n",
      "      },\n",
      "      \"object\": \"fine_tuning.job.checkpoint\",\n",
      "      \"step_number\": 80\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"ftchkpt-2e5a135c7dae47e8830dd6f90968965a\",\n",
      "      \"created_at\": 1756147586,\n",
      "      \"fine_tuned_model_checkpoint\": \"gpt-4.1-2025-04-14.ft-d04bf4eb1348467fa3678fdae1e63dc8:ckpt-step-40\",\n",
      "      \"fine_tuning_job_id\": \"ftjob-d04bf4eb1348467fa3678fdae1e63dc8\",\n",
      "      \"metrics\": {\n",
      "        \"full_valid_loss\": 1.7812775124748834,\n",
      "        \"full_valid_mean_token_accuracy\": 0.5575539568345323,\n",
      "        \"step\": 40.0,\n",
      "        \"train_loss\": 2.048199415206909,\n",
      "        \"train_mean_token_accuracy\": 0.5555555820465088,\n",
      "        \"valid_loss\": 1.396338939666748,\n",
      "        \"valid_mean_token_accuracy\": 0.5833333333333334\n",
      "      },\n",
      "      \"object\": \"fine_tuning.job.checkpoint\",\n",
      "      \"step_number\": 40\n",
      "    }\n",
      "  ],\n",
      "  \"has_more\": false,\n",
      "  \"object\": \"list\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = client.fine_tuning.jobs.checkpoints.list(job_id)\n",
    "print(response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94a4752",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. Final Training Run Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e2d17ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"ftjob-d04bf4eb1348467fa3678fdae1e63dc8\",\n",
      "  \"created_at\": 1756144701,\n",
      "  \"error\": null,\n",
      "  \"fine_tuned_model\": \"gpt-4.1-2025-04-14.ft-d04bf4eb1348467fa3678fdae1e63dc8\",\n",
      "  \"finished_at\": 1756149364,\n",
      "  \"hyperparameters\": {\n",
      "    \"batch_size\": 1,\n",
      "    \"learning_rate_multiplier\": 2.0,\n",
      "    \"n_epochs\": 3\n",
      "  },\n",
      "  \"model\": \"gpt-4.1-2025-04-14\",\n",
      "  \"object\": \"fine_tuning.job\",\n",
      "  \"organization_id\": null,\n",
      "  \"result_files\": [\n",
      "    \"file-c39c3cfde22648948c6fdd6cfc1279ce\"\n",
      "  ],\n",
      "  \"seed\": 101,\n",
      "  \"status\": \"succeeded\",\n",
      "  \"trained_tokens\": 9900,\n",
      "  \"training_file\": \"file-f234ff928f344a998497193d27f19239\",\n",
      "  \"validation_file\": \"file-017e3d8843104ac880e523b42624ee46\",\n",
      "  \"estimated_finish\": 1756146946,\n",
      "  \"integrations\": null,\n",
      "  \"metadata\": null,\n",
      "  \"method\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Retrieve fine_tuned_model name\n",
    "\n",
    "response = client.fine_tuning.jobs.retrieve(job_id)\n",
    "\n",
    "print(response.model_dump_json(indent=2))\n",
    "fine_tuned_model = response.fine_tuned_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9716a1fd",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 10. Deploy Fine-Tuned Model\n",
    "\n",
    "Follow the new guidance [at this document](https://learn.microsoft.com/en-us/azure/ai-foundry/openai/how-to/fine-tune-test?tabs=portal) to learn how to use the _developer tier_ for more cost effective testing. For now let's use the [Portal option](https://learn.microsoft.com/en-us/azure/ai-foundry/openai/how-to/fine-tune-test?tabs=portal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bda6ca",
   "metadata": {},
   "source": [
    "--- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ec02f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Access token acquired and stored in variable 'access_token'.\n"
     ]
    }
   ],
   "source": [
    "# First get a valid access token using the Azure CLI\n",
    "import subprocess\n",
    "\n",
    "# Run the az command to get an access token\n",
    "result = subprocess.run(\n",
    "    [\"az\", \"account\", \"get-access-token\", \"--query\", \"accessToken\", \"-o\", \"tsv\"],\n",
    "    capture_output=True, text=True, check=True\n",
    ")\n",
    "access_token = result.stdout.strip()\n",
    "print(\"Access token acquired and stored in variable 'access_token'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7f1152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ........... COMMENTED OUT FOR NOW - DEPLOYMENT DONE MANUALLY VIA PORTAL ......\n",
    "\n",
    "'''\n",
    "# Deploy fine-tuned model\n",
    "\n",
    "import json\n",
    "import requests\n",
    "\n",
    "token = os.getenv(\"TEMP_AUTH_TOKEN\")\n",
    "subscription = \"<YOUR_SUBSCRIPTION_ID>\"\n",
    "resource_group = \"<YOUR_RESOURCE_GROUP_NAME>\"\n",
    "resource_name = \"<YOUR_AZURE_OPENAI_RESOURCE_NAME>\"\n",
    "model_deployment_name = \"gpt-4o-mini-2024-07-18-ft\" # Custom deployment name you chose for your fine-tuning model\n",
    "\n",
    "deploy_params = {'api-version': \"2024-10-01\"} # Control plane API version\n",
    "deploy_headers = {'Authorization': 'Bearer {}'.format(token), 'Content-Type': 'application/json'}\n",
    "\n",
    "deploy_data = {\n",
    "    \"sku\": {\"name\": \"standard\", \"capacity\": 1},\n",
    "    \"properties\": {\n",
    "        \"model\": {\n",
    "            \"format\": \"OpenAI\",\n",
    "            \"name\": \"<YOUR_FINE_TUNED_MODEL>\", #retrieve this value from the previous call, it will look like gpt-4o-mini-2024-07-18.ft-0e208cf33a6a466994aff31a08aba678\n",
    "            \"version\": \"1\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "deploy_data = json.dumps(deploy_data)\n",
    "\n",
    "request_url = f'https://management.azure.com/subscriptions/{subscription}/resourceGroups/{resource_group}/providers/Microsoft.CognitiveServices/accounts/{resource_name}/deployments/{model_deployment_name}'\n",
    "\n",
    "print('Creating a new deployment...')\n",
    "\n",
    "r = requests.put(request_url, params=deploy_params, headers=deploy_headers, data=deploy_data)\n",
    "\n",
    "print(r)\n",
    "print(r.reason)\n",
    "print(r.json())\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80778a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ........... COMMENTED OUT FOR NOW - DEPLOYMENT DONE MANUALLY VIA PORTAL ......\n",
    "'''\n",
    "# Deploying with Developer Tier\n",
    "#\n",
    "# to obtain the TOKEN parameter, simply access the Cloud Shell in the Azure portal \n",
    "# and execute the az account get-access-token command. This will generate the \n",
    "# necessary authorization token for your deployment tasks, making the process \n",
    "# efficient and straightforward.\n",
    "\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "\n",
    "token = os.getenv(\"<TOKEN>\") \n",
    "subscription = \"<YOUR_SUBSCRIPTION_ID>\"  \n",
    "resource_group = \"<YOUR_RESOURCE_GROUP_NAME>\"\n",
    "resource_name = \"<YOUR_AZURE_OPENAI_RESOURCE_NAME>\"\n",
    "model_deployment_name = \"gpt41-mini-candidate-01\" # custom deployment name that you will use to reference the model when making inference calls.\n",
    "\n",
    "deploy_params = {'api-version': \"2025-04-01-preview\"} \n",
    "deploy_headers = {'Authorization': 'Bearer {}'.format(token), 'Content-Type': 'application/json'}\n",
    "\n",
    "deploy_data = {\n",
    "    \"sku\": {\"name\": \"developertier\", \"capacity\": 50},\n",
    "    \"properties\": {\n",
    "        \"model\": {\n",
    "            \"format\": \"OpenAI\",\n",
    "            \"name\": <\"fine_tuned_model\">, #retrieve this value from the previous call, it will look like gpt41-mini-candidate-01.ft-b044a9d3cf9c4228b5d393567f693b83\n",
    "            \"version\": \"1\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "deploy_data = json.dumps(deploy_data)\n",
    "\n",
    "request_url = f'https://management.azure.com/subscriptions/{subscription}/resourceGroups/{resource_group}/providers/Microsoft.CognitiveServices/accounts/{resource_name}/deployments/{model_deployment_name}'\n",
    "\n",
    "print('Creating a new deployment...')\n",
    "\n",
    "r = requests.put(request_url, params=deploy_params, headers=deploy_headers, data=deploy_data)\n",
    "\n",
    "print(r)\n",
    "print(r.reason)\n",
    "print(r.json())\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393fd90c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 11. Use Deployed Customized Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cc53e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ........... COMMENTED OUT FOR NOW - TESTING DONE MANUALLY VIA PORTAL ......\n",
    "\n",
    "'''\n",
    "\n",
    "# Use the deployed customized model\n",
    "\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "  api_key = os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "  api_version = \"2024-10-21\"\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model = \"gpt-4o-mini-2024-07-18-ft\", # model = \"Custom deployment name you chose for your fine-tuning model\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Does Azure OpenAI support customer managed keys?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Yes, customer managed keys are supported by Azure OpenAI.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Do other Azure services support this too?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a528d03",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 12. DELETE DEPLOYMENT‚ÄºÔ∏è\n",
    "\n",
    "> [Developer Deployments](https://learn.microsoft.com/en-us/azure/ai-foundry/openai/how-to/fine-tune-test?tabs=portal#clean-up-your-deployment) will delete on their own after the 24-hour default window. For all others, delete manually.\n",
    "\n",
    "\n",
    "Unlike other types of Azure OpenAI models, fine-tuned/customized models have an hourly hosting cost associated with them once they're deployed. It's strongly recommended that once you're done with this tutorial and have tested a few chat completion calls against your fine-tuned model, that you delete the model deployment.\n",
    "\n",
    "Use this command from CLI to delete the deployed model where the placeholder variables should be replaced with the values for your deployment.\n",
    "\n",
    "```bash\n",
    "curl -X DELETE \"https://management.azure.com/subscriptions/<SUBSCRIPTION>/resourceGroups/<RESOURCE_GROUP>/providers/Microsoft.CognitiveServices/accounts/<RESOURCE_NAME>/deployments/<MODEL_DEPLOYMENT_NAME>api-version=2025-04-01-preview\" \\\n",
    "  -H \"Authorization: Bearer <TOKEN>\"\n",
    "```\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
