{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2a9dc4e",
   "metadata": {},
   "source": [
    "# 2 | Fine Tuning In Azure AI Foundry\n",
    "\n",
    "This section helps you setup the demo for Act 2. You will have done this work a day ahead of the breakout, and have it staged for convenience. \n",
    "\n",
    "You can then use the pre-recorded demos we provide or use your staged demo to create a personalized version of those recordings, if preferred. **Just stick to the suggested timings** to ensure you deliver the whole talk.\n",
    "\n",
    "By the end of this notebook you should have:\n",
    "\n",
    "1. Setup the Azure AI Foundry project\n",
    "1. Deployed a base model and validated it with the Playground\n",
    "1. Setup the `.env` file and configured it to reflect the deployment\n",
    "1. Got an intuitive sense for the customization journey with\n",
    "    - Deploying a base model and trying a default user query\n",
    "    - Prompt engineering it with examples & system message for tone & style\n",
    "    - Adding data for Retrieval Augmented Generation to get grounded responses\n",
    "    - Seeing the cost, latency and accuracy achievable without adapting model\n",
    "\n",
    "This will then set us up for Notebook 2 where we will do base fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af1f7ef",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2.1 Set The Stage\n",
    "\n",
    "Before we get to Act 2, we will have shown this slide that features the AI engineer's customization journey. Let's see if we can walk through this with a real project. Here are the main elements of the story we cover here:\n",
    "\n",
    "1. We have a Zava products database for grounding responses\n",
    "1. We know the desired \"tone & style\" we want to achieve\n",
    "1. Can we get the desired outcome with prompt engineering alone?\n",
    "1. Can we improve the outcome if we add data with RAG?\n",
    "1. Why should we continue to the customization step?\n",
    "\n",
    "_Note:_ The image shows a \"sample\" query-response. In our demo we may use a different one but we want to emphasize the model behavior change we want to see:\n",
    "\n",
    "1. Cora is a polite, factual and helpful assistant helping customers find Zava products.\n",
    "1. (Polite) Cora begins by acknowledging user query (\"Good Choice!\")\n",
    "1. (Factual) Cora is factual by providing grounded response (\"I... Eggshell Paint\")\n",
    "1. (Helpful) Cora is helpful by offering to follow-up (\"Would you like to know more ...\")\n",
    "\n",
    "![story](./06.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d971a8ed",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2.2 Understand Zava Data\n",
    "\n",
    "Zava is a retailer for home improvement products. In the `data/zava/` folder you fill find the following files:\n",
    "\n",
    "1. `products.json` - a JSON formatted product catalog with 420+ items\n",
    "1. `products.csv` - a CSV version of the same file\n",
    "1. `products-paints.csv` - the subset with a `PAINT & FINISHES` category\n",
    "\n",
    "To get this subset, we just filtered the file for lines with that category using GitHub Copilot (Agent Mode) for fast completions. This is what a sample product item in this category looks like. We do _NOT_ have the imags data locally, so we will focus instead of Q&A around other attributes of these products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a610eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Product 1 ===\n",
      "Name: Premium Interior Latex Flat\n",
      "Sku: PFIP000001\n",
      "Price: 40.0\n",
      "Description: High-quality flat interior paint with excellent coverage and hide, perfect for ceilings and low-traffic areas.\n",
      "Stock Level: 19\n",
      "Main Category: PAINT & FINISHES\n",
      "Subcategory: INTERIOR PAINT\n",
      "\n",
      "=== Product 2 ===\n",
      "Name: Interior Eggshell Paint\n",
      "Sku: PFIP000002\n",
      "Price: 44.0\n",
      "Description: Durable eggshell finish paint with subtle sheen, ideal for living rooms and bedrooms with easy cleanup.\n",
      "Stock Level: 80\n",
      "Main Category: PAINT & FINISHES\n",
      "Subcategory: INTERIOR PAINT\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "products_df = pd.read_csv('../../../data/zava/products-paints.csv')\n",
    "\n",
    "# Display the first two products in a readable format (excluding image_path)\n",
    "columns_to_show = ['name', 'sku', 'price', 'description', 'stock_level', 'main_category', 'subcategory']\n",
    "\n",
    "# Pretty print the first 2 products for example\n",
    "for i in range(min(2, len(products_df))):\n",
    "    print(f\"=== Product {i+1} ===\")\n",
    "    for col in columns_to_show:\n",
    "        print(f\"{col.replace('_', ' ').title()}: {products_df.iloc[i][col]}\")\n",
    "    print()  # Empty line between products"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ce186b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2.2 Create Sample Q&A Data\n",
    "\n",
    "Let's get a few examples of question-answer pairs that reflect our **desired tone and style** for Cora. For convenience, we just generated these using GitHub Copilot in Agent Mode, studying the `products-paints.csv` file with this guidance:\n",
    "\n",
    "**You may need to revise the guidance interactively**\n",
    "\n",
    "```txt\n",
    "Study the `data/zava/products-paints.csv` file to understand the product catalog details. We are generating sample customer support question-answer pairs in a JSONL format for fine-tuning.\n",
    "\n",
    "Here is an example of a valid question-answer pair:\n",
    "{\n",
    "  \"question\": \"Do you have any paint that works well in bathrooms?\",\n",
    "  \"answer\": \"Yes! Our Interior Semi-Gloss Paint has moisture resistance, perfect for bathrooms. Need more details?\"\n",
    "}\n",
    "\n",
    "Use this as a template to generate 10 additional question-answer pairs in a file called `qa-fewshot.jsonl` in the data/zava folder where:\n",
    "1. Each response starts with a brief and friendly acknowledgement (for example: \"Yes!\" or \"Of course!\")\n",
    "2. Response then provides factual answer using data in the products-paints.csv file\n",
    "3. Response ends with offer to help do a follow-up task related to that response\n",
    "\n",
    "Avoid duplicate questions. \n",
    "Refine answers to be less chatty and more actionable\n",
    "Have questions on different aspects of product (price, stock etc.)\n",
    "Have responses that reflect different kinds of customer support behaviors (not in stock, currently on sale, the requested product will not meet the stated user requirement )\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64dd82c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Q&A pairs created: 10\n",
      "\n",
      "--- Example 1 ---\n",
      "Question: Do you have any paint that works well in bathrooms?\n",
      "Answer: Yes! Our Interior Semi-Gloss Paint has moisture resistance, perfect for bathrooms. Need details?\n",
      "\n",
      "--- Example 2 ---\n",
      "Question: What's your most affordable interior paint option?\n",
      "Answer: I can help! Our Drywall Primer is $29, great for new drywall. Want a topcoat too?\n",
      "\n",
      "--- Example 3 ---\n",
      "Question: I need paint for my deck - what do you recommend?\n",
      "Answer: Absolutely! Deck and Fence Stain at $42 with UV protection. Check stock levels?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Read the JSONL file and pretty print the first 3 question-answer pairs\n",
    "jsonl_file_path = '../../../data/zava/qa-fewshot.jsonl'\n",
    "\n",
    "# Generated pairs\n",
    "print(f\"Total Q&A pairs created: {sum(1 for line in open(jsonl_file_path))}\\n\")\n",
    "\n",
    "# Pretty print the first 3 Q&A pairs for example\n",
    "with open(jsonl_file_path, 'r') as file:\n",
    "    for i, line in enumerate(file):\n",
    "        if i >= 3:  # Only show first 3\n",
    "            break\n",
    "        \n",
    "        qa_pair = json.loads(line.strip())\n",
    "        \n",
    "        print(f\"--- Example {i+1} ---\")\n",
    "        print(f\"Question: {qa_pair['question']}\")\n",
    "        print(f\"Answer: {qa_pair['answer']}\")\n",
    "        print()  # Empty line between pairs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c7423b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2.3 Create Foundry Project & Resource\n",
    "\n",
    "This helps organize your work for a specific use case or AI solution. \n",
    "There are [two types of projects](https://ai.azure.com/doc/azure/ai-foundry/how-to/migrate-project?) you can create - Hub-based (for machine learning studio use) and Foundry-based (for generative and agentic AI). **Use Foundry Projects** to get streamlined setup, workflow and governance for a _platform-as-a-service_ approach (unified SDK, API) - recommended for new projects!\n",
    "\n",
    "![Project types](https://learn.microsoft.com/azure/ai-foundry/media/migrate-project/project-structure.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4457ef55",
   "metadata": {},
   "source": [
    "\n",
    "Let's create the project now.\n",
    "\n",
    "1. Visit [https://ai.azure.com/allResources](https://ai.azure.com/allResources) \n",
    "1. Log in with Azure credentials to view resources.\n",
    "1. Click **Create New** and [follow instructions](https://ai.azure.com/doc/azure/ai-foundry/how-to/create-projects) to create a Foundry project.\n",
    "1. Completes in minutes. **You see a Project overview page**.\n",
    "\n",
    "Note these features on that page - we'll revisit them later:\n",
    "1. Overview page - has endpoints and keys\n",
    "1. Sidebar menu - has Model catalog & Playgrounds options\n",
    "1. Sidebar menu - has \"My Assets\" section with Models & Endpoints\n",
    "1. Sidebar menu - has \"Management Center\" for resource management"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb55f03a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2.4 Deploy Base Model & Iterate\n",
    "\n",
    "To get started on a model customization journey, the first step is to **select a base model** for our Cora chatbot. Let's start by deploying a popular general-purpose large language model (`gpt-4.1`).\n",
    "\n",
    "We can then see if it meets our needs out of the box with a simple system message and test prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e359ebb",
   "metadata": {},
   "source": [
    "### 2.4.1 Deploy GPT-4.1\n",
    "\n",
    "1. Return to the \"Project Overview\" tab in Azure AI Foundry portal\n",
    "1. Click on the \"Model catalog\" option (left sidebar) in the project overview.\n",
    "1. Search for `gpt-4.1` model - click \"Use this model\" and complete deployment\n",
    "1. You should see the **Model Details** card.\n",
    "1. Click **Open in playground** to validate it interactively.\n",
    "\n",
    "You should see something like this:\n",
    "\n",
    "![GPT4 Playground](./00-playground-gpt41.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e733272",
   "metadata": {},
   "source": [
    "### 2.4.2 Set System Message\n",
    "\n",
    "The Playground provides these elements for customization:\n",
    "1. **System Prompt** - Give model instructions & context for request. \n",
    "1. **Add Section** - drop down (examples, variables, safety system messages)\n",
    "1. **Add Your Data** - launch wizard to connect to external data sources\n",
    "1. **Parameters** - max completion tokens, temperature, top-p etc.\n",
    "\n",
    "Copy this to System Message window and click \"Apply\" to enforce it.\n",
    "\n",
    "> You are Cora - a polite, factual and helpful assistant for Zava customers.\n",
    "\n",
    "Now, try this sample prompt to see response _with default base model_.\n",
    "\n",
    "> Do you have any paint that works well in bathrooms?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d9b760",
   "metadata": {},
   "source": [
    "**WHAT WE SEE**\n",
    "\n",
    "1. Response is not grounded (it fabricated Zava products)\n",
    "1. Tone & style are not what we want (very verbose)\n",
    "1. Response was fairly quick but used 175 tokens\n",
    "\n",
    "![Response](./01-prompt-gpt41.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b6c4d9",
   "metadata": {},
   "source": [
    "**DESIRED TONE & STYLE**\n",
    "\n",
    "> Yes! Our Interior Semi-Gloss Paint has moisture resistance, perfect for bathrooms. Need details?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f410b21",
   "metadata": {},
   "source": [
    "### 2.4.3 Add Instructions & Examples\n",
    "\n",
    "Use the **Add section** to add examples. You will be asked to enter \"User\" and \"Assistant\" sections for each example. We'll use the Q&A samples we created where the Question goes into User dialog and Answer goes into Assistant dialog. For now, let's just add 5 examples reflecting different situations.\n",
    "\n",
    "\n",
    "User: \"Do you have any paint that works well in bathrooms?\"\n",
    "\n",
    "Assistant: \"Yes! Our Interior Semi-Gloss Paint has moisture resistance, perfect for bathrooms. Need details?\"\n",
    "\n",
    "User: \"What's your most affordable interior paint option?\"\n",
    "\n",
    "Assistant: \"I can help! Our Drywall Primer is $29, great for new drywall. Want a topcoat too?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2e16a1",
   "metadata": {},
   "source": [
    "### 2.4.4 Test Prompt-Engineered Tone\n",
    "\n",
    "You can now use one of our sample questions (that was not in the example) and see if the response is **similar** to what we expected\n",
    "\n",
    "| Sample | Sample Answer |\n",
    "|:---|:---|\n",
    "| \"I need paint for my deck - what do you recommend?\" | \"Absolutely! Deck and Fence Stain at $42 with UV protection. Check stock levels?\"|\n",
    "| \"Do you have any eco-friendly paint options?\" | \"Yes! Zero VOC Interior Paint at $52 ensures healthy air quality. Need color options?\" |\n",
    "| \"I'm looking for paint tray liners - are they in stock?\" | \"Unfortunately, Paint Tray Liner Set is out of stock. Try our Disposable Paint Tray Set instead?\" |\n",
    "\n",
    "Let's see what we actually get."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6674498f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a97ec83",
   "metadata": {},
   "source": [
    "**Answer 1**: Using few-shot examples we were able to get the tone and style _closer_ to what we need. \n",
    "\n",
    "But note:\n",
    "1. The answer is not factual. This product does not exist.\n",
    "1. The style is closer to what we want - but it is a bit longer than what we suggest in our examples. We can improve it.\n",
    "1. Every prompt will now add 63 tokens to carry those examples to \"prompt engineer\" responses effectively. \n",
    "1. If we want to have more diverse examples (e.g., apology tone for out of stock etc.) this length will increase.\n",
    "1. We have a fixed context window so we can only add a limited number of examples \n",
    "\n",
    "![Example 1](./02-fewshot-gpt41-1.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08408a41",
   "metadata": {},
   "source": [
    "**Answer 2** - \n",
    "\n",
    "1. This is closer in style with a shorter response - but it is not factual. \n",
    "1. Few shot examples are taking up prompt length space again.\n",
    "1. The style is not perfect - note how our example responses always cited prices but model does not\n",
    "\n",
    "![Example 2](./02-fewshot-gpt41-2.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ad64e2",
   "metadata": {},
   "source": [
    "## 2.5 Add Your Data (For RAG)\n",
    "\n",
    "For the next step of customization, we'll use RAG to ground responses in our product data. To do this we need to take 3 steps:\n",
    "\n",
    "1. Setup environment variables - for code-first use\n",
    "1. Authenticate with Azure - to use managed identity\n",
    "1. Create an Azure AI Search resource - and add connection to Foundry project\n",
    "1. Run scripts - to update RBAC roles and create index from data\n",
    "1. Use created index in playground - verify we get grounded responses\n",
    "\n",
    "**These steps are being done manually for simplicity. We may replace them later with an AZD template or Azure CLI scripts for convenience, once those are tested and validated**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248d5ccf",
   "metadata": {},
   "source": [
    "### 2.5.1 Authenticate With Azure \n",
    "\n",
    "Use `az login --tenant <tenant-id>` to authenticate with Azure from the VS Code terminal. This process will trigger a workflow that will complete authentication using a device code in the browser. Once completed, return here and run the next cell to verify you are authenticated\n",
    "\n",
    "**Logging in allows us to use Managed Identity later for keyless authentication (recommended) in code-first examples later**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009878ca",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Check if you are logged into Azure \n",
    "!az account show\n",
    "\n",
    "# If you are not logged in you will see a message like \n",
    "#    `Please run 'az login' to setup account.`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe22a0c1",
   "metadata": {},
   "source": [
    "### 2.5.2 Create `.env` file\n",
    "\n",
    "1. Copy over `.env.sample` to `.env` - we'll fill in various values here as we go\n",
    "1. Start by completing the first section for your Azure AI Foundry resource.\n",
    "    - AZURE_OPENAI_API_KEY - from the Azure AI Foundry Overview page \n",
    "    - AZURE_OPENAI_ENDPOINT - from the Azure AI Foundry Overview page \n",
    "    - AZURE_OPENAI_API_VERSION - leave default value of \"2025-02-01-preview\"  \n",
    "1. Start filling in the Azure AI Search section\n",
    "    - AZURE_AISEARCH_ENDPOINT - **we will do this in the next section**\n",
    "    - AZURE_AISEARCH_INDEX - set this to \"zava-products\"\n",
    "    - AZURE_AISEARCH_RESOURCE_GROUP - from the Azure AI Foundry Overview page (right)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f2af7c",
   "metadata": {},
   "source": [
    "### 2.5.3 Create Azure AI Search Resource\n",
    "\n",
    "We want to make our data accessible to the model for RAG. Use [this guidance](https://learn.microsoft.com/azure/ai-foundry/tutorials/copilot-sdk-create-resources#create-search) to get this done, next.\n",
    "\n",
    "1. Visit your AI Project Overview page - look for the **Resource Group** link (panel, right)\n",
    "1. Click to visit Azure Portal - use [this link](https://portal.azure.com/#create/Microsoft.Search) to create AI Search resource **for that resource group**\n",
    "1. Use a relevant name and default location - **make sure you pick Standard Pricing Tier**\n",
    "1. Click **Review+Create** to complete -- this will setup Azure AI Search resource in the same resource group\n",
    "1. Wait till done - click **Go to deployed resource** to see the Azure AI Search resource\n",
    "1. Look for the `Url` link in essentials - **use it to update .env value for AZURE_AISEARCH_ENDPOINT**\n",
    "1. Visit the `Settings > Keys` blade for Azure AI Search - switch API Access Control to \"Both\"\n",
    "\n",
    "This last step is needed in order to allow Playground to access index seamlessly. Our local development uses only managed identity so we don't need to store the key in our environment variables.\n",
    "\n",
    "_Note: This tier has a non-trivial cost per month. Make sure you tear this down as soon as your breakout session is over_."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7921420f",
   "metadata": {},
   "source": [
    "### 2.5.4 Create Azure AI Search Index\n",
    "\n",
    "Before we can run the notebook that creates the index, we need to make sure our user identity has the right RBAC permissions.\n",
    "\n",
    "1. Open a VS Code Terminal - make sure you are in the root directory\n",
    "1. Run this command `./data/scripts/01-update-roles.sh` - takes a minute or two to complete\n",
    "1. You should now be set to run the notebook that creates the index!!\n",
    "\n",
    "We also need to make sure we have the `text-embedding-ada-002` model deployed in our Azure AI Foundry project to help create the vector search indexesx. \n",
    "\n",
    "1. Return to Azure AI Foundry - click your project Overview\n",
    "1. Go to Model Catalog - search for `text-embedding-ada-002` and deploy it.\n",
    "1. It should compelete within minutes - verify the `Models + endpoints` now shows the model.\n",
    "\n",
    "Return to the VS Code editor and open the `data/zava/02-create-aisearch-index.ipynb` notebook\n",
    "\n",
    "1. Select Kernel - default 3.12 is fine\n",
    "1. Run All - all cells in notebook should complete successfully\n",
    "1. The last cell output should show something like this\n",
    "\n",
    "    ```txt\n",
    "    Uploading 51 Zava products to index zava-products\n",
    "    Successfully uploaded 51 products to the search index!\n",
    "    The Zava product catalog is now ready for semantic search.\n",
    "    ```\n",
    "\n",
    "**Let's verify the index, next!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c2322e",
   "metadata": {},
   "source": [
    "### 2.5.5 Verify Azure AI Search Index\n",
    "\n",
    "1. Visit the Azure Portal Azure AI Search resource - click \"Search Explorer\".\n",
    "1. You should see a Search Explorer with \"zava-products\" as an indext\n",
    "1. Enter a sample user query - e.g., `Do you have any paint that works well in bathrooms?`\n",
    "1. Note that the _retrieved result_ contains \"Interior Semi-Gloss Paint\" - the right product!\n",
    "\n",
    "![Index](./03-search-index.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3039c2",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "source": [
    "### 2.5.6 Use Index In Playground\n",
    "\n",
    "1. Return to the Playground where we were testing the base model.\n",
    "1. Now click \"Add Data\" - then click **Add Data Source** \n",
    "1. Select \"Azure AI Search\" - the wizard will help you complete the flow\n",
    "1. You should see \"zava-products\" as an index option - select it\n",
    "1. Select the \"Add vector search\" option - use pre-deployed `text-embedding-ada-002` model \n",
    "1. (Optional) select custom field mapping - view default mappings (leave them as is)\n",
    "1. Data management - leave defaults (Hybrid + semantic search)\n",
    "1. Authentication - select API key for now (will need to add AD roles support later)\n",
    "\n",
    "![Add data](./04-add-data-source.png)\n",
    "\n",
    "To use Managed Identity for Authentication, we need to allow services [to authorize each other](https://learn.microsoft.com/en-us/azure/ai-foundry/openai/how-to/on-your-data-configuration#role-assignments). This requires a few additional steps that we will fix later\n",
    "**`TODO`** - update this step for managed identity.\n",
    "\n",
    "For now, we'll move ahead by allowing API KEY usage instead.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3659ed3b",
   "metadata": {},
   "source": [
    "### 2.5.7 Test Prompt with Data\n",
    "\n",
    "Return to the Playground. You will now see the Azure AI Search index is a data source, your system message provides guidance and you have two examples for few-shot training. Try the same request as before and you will see something like this. _Note: Since LLMs are stochastic, your exact response may vary_.\n",
    "\n",
    "Note that now we get a response that is _factually correct_ - it identifies a valid product in the Zava database that is relevant to the user query. However, it may not be the _precise_ response we were looking for. To test this out, visit the Azure AI Search resource \"explorer\" and run these two queries.\n",
    "\n",
    "1. \"Deck stain\" => top answer \"Deck and Fence Stain\" - _This is the answer we want_\n",
    "1. \"Paint deck\" => top answer \"Solid Color Deck Stain\" - _This is the answer we get_.\n",
    "\n",
    "![Grounded](./05-withrag-gpt41.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9deeb78",
   "metadata": {},
   "source": [
    "\n",
    "We can improve this with an enhanced prompt template and orchestration framework etc. - but for now, we just wanted to demonstrate three things:\n",
    "\n",
    "1. Base models will not reflect a desired tone, style - or be grounded in your data\n",
    "1. Prompt engineering (with system message and few show examples) - can improve tone/style \n",
    "1. Adding data (RAG with vector search) - can improve groundedness in your data\n",
    "1. Both these \"customization\" steps add costs (prompt length, network latency, context window usage)\n",
    "1. To improve performance, we may need more data, more \n",
    "\n",
    "But each step adds a certain cost/accuracy tradeoff\n",
    "1. Improve tone with more few shot examples - but this increases prompt length\n",
    "1. Improve groundedness by retrieving more examples - but results are still not precise\n",
    "1. Few shot examples are limited - having more examples would help improve tone and style\n",
    "1. RAG retrieves grounded results - improving how they are used by model would improve precision\n",
    "\n",
    "**How can we customize the model further to meet these targets?** This is where fine-tuning can help.\n",
    "\n",
    "![More RAG](./06-morerag-gpt41.png)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
